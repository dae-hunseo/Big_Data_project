{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "304de2a1",
   "metadata": {},
   "source": [
    "# 기본 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd43360",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T06:19:27.153225Z",
     "start_time": "2022-12-26T06:19:25.176360Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587481fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T06:19:27.257947Z",
     "start_time": "2022-12-26T06:19:27.245979Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5118ab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T06:19:28.690194Z",
     "start_time": "2022-12-26T06:19:28.668201Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 오차행렬 및 평가지표 출력\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    \n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n",
    "\n",
    "\n",
    "# 임계값 조정하여 오차행렬 및 평가지표 출력\n",
    "def get_eval_by_threshold(y_test, pred, pred_proba_c1, thresholds):\n",
    "    pred_proba_c1 = pred_proba_c1.reshape(-1, 1)\n",
    "    for custom_threshold in thresholds:\n",
    "        bina = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = bina.transform(pred_proba_c1)\n",
    "        print('분류 임계값 :', custom_threshold)\n",
    "        get_clf_eval(y_test, custom_predict, pred_proba_c1)\n",
    "    \n",
    "\n",
    "# 임계값별로 precison_recall_curve 그리기\n",
    "def precision_recall_curve_plot(y_test, pred_proba_c1): \n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision') \n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
    "\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    \n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75ac8ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T08:21:11.128092Z",
     "start_time": "2022-12-26T08:21:11.103199Z"
    }
   },
   "outputs": [],
   "source": [
    "def dict_to_params(model, params_dict):\n",
    "    for key, value in params_dict.items():\n",
    "        eval(f\"model.set_params({key}=value)\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def grid_search_eval(model, params):\n",
    "    model_list = []\n",
    "    \n",
    "    gs = GridSearchCV(estimator=model, param_grid=params, scoring=[\"accuracy\", \"f1\", \"recall\", \"precision\"], \n",
    "                      refit=False, cv=3, verbose=2)\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    result = pd.DataFrame(gs.cv_results_)\n",
    "    \n",
    "    best_results = result[(result[\"rank_test_accuracy\"]<=3) | (result[\"rank_test_f1\"]<=3) | \n",
    "                          (result[\"rank_test_recall\"]<=3) | (result[\"rank_test_precision\"]<=3)]\n",
    "    \n",
    "    for best_params in best_results[\"params\"]:\n",
    "        model_list.append(dict_to_params(copy.deepcopy(model), best_params))\n",
    "    \n",
    "    for best_model in model_list:\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        pred = best_model.predict(X_test)\n",
    "        try:\n",
    "            pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "            print(\"=\"*100, \"\\n\", best_model)\n",
    "            print(best_model.score(X_train, y_train))\n",
    "            print(best_model.score(X_test, y_test))\n",
    "            get_clf_eval(y_test, pred, pred_proba)\n",
    "        except:\n",
    "            print(\"=\"*200)\n",
    "            print(\"=\"*100, \"\\n\", best_model)\n",
    "            print(best_model.score(X_train, y_train))\n",
    "            print(best_model.score(X_test, y_test))\n",
    "            get_clf_eval(y_test, pred)\n",
    "    \n",
    "    return model_list, result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c091f",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c10fa5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T06:19:36.943889Z",
     "start_time": "2022-12-26T06:19:36.927696Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    brfss = pd.read_csv(\"../data/brfss.csv\")\n",
    "    X = brfss.drop([\"HEARTDISEASE\", \"ALCOHOL\"], axis=1)\n",
    "    y = brfss[\"HEARTDISEASE\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "    smote = SMOTE()\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    print(y_train.value_counts())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brfss = pd.read_csv(\"../data/brfss.csv\")\n",
    "X = brfss.drop([\"HEARTDISEASE\", \"ALCOHOL\"], axis=1)\n",
    "y = brfss[\"HEARTDISEASE\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb5901",
   "metadata": {},
   "source": [
    "### with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a46dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T03:05:10.619369Z",
     "start_time": "2022-12-26T03:05:09.050879Z"
    }
   },
   "outputs": [],
   "source": [
    "brfss = pd.read_csv(\"../data/brfss.csv\")\n",
    "X = brfss.drop([\"HEARTDISEASE\", \"ALCOHOL\"], axis=1)\n",
    "y = brfss[\"HEARTDISEASE\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e378da",
   "metadata": {},
   "source": [
    "# 할 일\n",
    "- 하이퍼 파라미터 튜닝\n",
    "    - 각 모델 document 보면서 찾아보기\n",
    "- 임계점 변경\n",
    "    - 변경해보면서 최적값 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a86cf6",
   "metadata": {},
   "source": [
    "# 박민정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c3227",
   "metadata": {},
   "source": [
    "## Data\n",
    "- 건강검진 데이터의 KIDNEY 조건 변경 검토\n",
    "```\n",
    "data[\"KIDNEY\"] = data.apply(lambda x: 1 if x[\"요단백\"]>=3 or x[\"혈청크레아티닌\"]>1.7 or x[\"혈청크레아티닌\"]<0.8 else 0, axis=1)\n",
    "0    1295062\n",
    "1     744182\n",
    "```\n",
    "```\n",
    "data[\"KIDNEY\"] = data.apply(lambda x: 1 if x[\"요단백\"]>=3 and (x[\"혈청크레아티닌\"]>1.7 or x[\"혈청크레아티닌\"]<0.8) else 0, axis=1)\n",
    "0    2020722\n",
    "1      18522\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ca6152",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03ff39",
   "metadata": {},
   "source": [
    "### base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f303f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T00:47:21.235224Z",
     "start_time": "2022-12-26T00:47:20.560233Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1eb88e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T08:07:30.552324Z",
     "start_time": "2022-12-23T08:07:30.348854Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 임계값 그래프\n",
    "precision_recall_curve_plot(y_test, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc729d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T08:08:43.728242Z",
     "start_time": "2022-12-23T08:08:42.584612Z"
    }
   },
   "outputs": [],
   "source": [
    "# 임계값 조정\n",
    "thresholds = [.5, .55, .6, .65, .7, .75, .8, .85]\n",
    "get_eval_by_threshold(y_test, pred, pred_proba, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954a74d",
   "metadata": {},
   "source": [
    "### 모델링\n",
    "- 하이퍼 파라미터    \n",
    "    - criterion: ```\"gini\", \"entropy\", \"log_loss\"```\n",
    "    - splitter: ```\"best\", \"random\"```\n",
    "    - max_depth: ```~~~~~~~~~~~~~```   \n",
    "    - max_features: ```\"sqrt\", \"log2\", None```\n",
    "    - min_impurity_decrease: ```~~~~~~~~~~~~~~```\n",
    "    - class_weight: ```\"balanced\", None```\n",
    "    - ccp_alpha: ```~~~~~~~~~~~~~~~~~~```\n",
    "- 사용하지 않은 하이퍼 파라미터\n",
    "    - min_samples_split: int or float, default=2\n",
    "    - min_samples_leaf: int or float, default=1\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb72ac6e",
   "metadata": {},
   "source": [
    "#### 트리 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa17fc6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-26T05:25:42.428Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": range(1, 10, 1),\n",
    "    \"min_samples_split\": range(2, 102, 10),\n",
    "    \"min_samples_leaf\": range(1, 10, 1),\n",
    "    \"max_leaf_nodes\": range(1, 11, 1),\n",
    "    \"min_impurity_decrease\": np.arange(0.0001, 0.001, 0.0001),\n",
    "    \"ccp_alpha\": np.arange(0.0, 0.04, 0.005),\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_data()\n",
    "model = DecisionTreeClassifier()\n",
    "model_list, result = grid_search_eval(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9a3f45",
   "metadata": {},
   "source": [
    "#### 전체 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03767f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-26T05:22:08.650Z"
    }
   },
   "outputs": [],
   "source": [
    "all_params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"splitter\": [\"best\", \"random\"], \n",
    "    \"max_depth\": range(1, 10, 1),\n",
    "    \"min_samples_split\": range(2, 102, 10),\n",
    "    \"min_samples_leaf\": range(1, 21, 1),\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"max_leaf_nodes\": range(1, 11, 1),\n",
    "    \"min_impurity_decrease\": np.arange(0.0001, 0.001, 0.0001),\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"ccp_alpha\": np.arange(0.0, 0.04, 0.005),\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_data()\n",
    "model = DecisionTreeClassifier()\n",
    "model_list, result = grid_search_eval(model, all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16c43e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T00:27:57.489498Z",
     "start_time": "2022-12-26T00:27:57.470549Z"
    }
   },
   "source": [
    "### 임계값 변경\n",
    "- 의료 데이터이므로 높이는 쪽으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412cf9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "068e133a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T05:30:52.564141Z",
     "start_time": "2022-12-23T05:30:52.556165Z"
    }
   },
   "source": [
    "## SGDClassifier\n",
    "- 하이퍼 파라미터\n",
    "    - loss: ```\"hinge\", \"log_loss\", \"modified_huber\", \"squared_hinge\", \"perceptron\"```\n",
    "        - \"squared_error\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\": regression에서 사용하는 함수라서 제외\n",
    "    - penalty: ```\"l2\", \"l1\", \"elasticnet\", None```\n",
    "    - alpha: ```0.0001, 0.001, 0.01, 0.1```\n",
    "    - learning_rate: ```\"constant\", \"optimal\", \"invscaling\"```\n",
    "    - class_weight: ```\"balanced\", None```\n",
    "\n",
    "- 고정된 하이퍼 파라미터\n",
    "    - early_stopping: ```True```\n",
    "    - n_iter_no_change: ```5```\n",
    "- 사용하지 않은 하이퍼 파라미터\n",
    "    - fit_intercept\n",
    "    - max_iter\n",
    "    - tol\n",
    "    - shuffle\n",
    "    - epsilon    \n",
    "    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705da419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T07:14:11.394518Z",
     "start_time": "2022-12-23T07:14:10.210298Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier(loss=\"log_loss\", max_iter=10)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f33d5209",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T06:54:07.814201Z",
     "start_time": "2022-12-26T06:49:35.103603Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    286732\n",
      "0.0    286732\n",
      "Name: HEARTDISEASE, dtype: int64\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   1.2s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   1.1s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   1.3s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   1.2s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=constant, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=hinge, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=elasticnet; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=log_loss, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=invscaling, loss=modified_huber, penalty=None; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "576 fits failed out of a total of 864.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "576 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 890, in fit\n",
      "    return self._fit(\n",
      "  File \"D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 658, in _fit\n",
      "    self._validate_params()\n",
      "  File \"D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 148, in _validate_params\n",
      "    raise ValueError(\"eta0 must be > 0\")\n",
      "ValueError: eta0 must be > 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.67927542 0.6792667  0.67927368 0.67927019 0.70413662 0.70504164\n",
      " 0.70504687 0.70423427 0.70451502 0.69984513 0.70416277 0.69951556\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.67926496 0.67927368 0.67926322 0.67926845 0.70522822 0.70502246\n",
      " 0.70401804 0.70463534 0.70210684 0.70583332 0.69988003 0.70284098\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.67925101 0.67925101 0.67925101 0.67925101 0.70480797 0.70401106\n",
      " 0.70481146 0.7050242  0.70442085 0.70461616 0.70467719 0.70479925\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.67925101 0.67925101 0.67925101 0.67925101 0.70480972 0.70434413\n",
      " 0.70481146 0.70512709 0.70478705 0.70450106 0.70456384 0.70479228\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.67925101 0.67925101 0.67925101 0.67925101 0.70452722 0.69776656\n",
      " 0.70404245 0.70503292 0.70468068 0.70311476 0.70455687 0.70470858\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.67925101 0.67925101 0.67925101 0.67925101 0.70452722 0.69705509\n",
      " 0.70404419 0.70512185 0.70459    0.70390469 0.70439644 0.7047173\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.6841528  0.67925101 0.68148306 0.69092043 0.70060719 0.5\n",
      " 0.69384303 0.70361697 0.703889   0.67929983 0.70096815 0.70479053\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.68415454 0.67925101 0.68148131 0.68098782 0.70060719 0.5\n",
      " 0.69374015 0.70418718 0.703889   0.67930332 0.69910753 0.70479228\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69588982 0.69587903 0.69588766 0.69588335 0.70882959 0.71586805\n",
      " 0.71587914 0.708972   0.71530469 0.69249893 0.7087211  0.69380653\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69587688 0.69588766 0.69587473 0.69588119 0.71663369 0.71584238\n",
      " 0.70863125 0.70935193 0.70390877 0.71817949 0.69803483 0.70739606\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69585963 0.69585963 0.69585963 0.69585963 0.71550151 0.70862279\n",
      " 0.71550583 0.71584648 0.70898536 0.715404   0.71522079 0.71549072\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69585963 0.69585963 0.69585963 0.69585963 0.71550368 0.70879424\n",
      " 0.71550583 0.71601382 0.71547562 0.70911952 0.71505626 0.71548208\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69585963 0.69585963 0.69585963 0.69585963 0.71493622 0.70068791\n",
      " 0.71374961 0.71586189 0.71528445 0.71170428 0.71500845 0.71531516\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69585963 0.69585963 0.69585963 0.69585963 0.71493622 0.69940999\n",
      " 0.71375179 0.71600735 0.71510887 0.71317088 0.7145569  0.71532596\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.70288977 0.69585963 0.69904205 0.70703203 0.70641017 0.44444444\n",
      " 0.693991   0.71308908 0.71315131 0.69592    0.70746217 0.71547992\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7028919  0.69585963 0.69903991 0.69838339 0.70641017 0.66666667\n",
      " 0.69385373 0.71414666 0.71315131 0.69592432 0.70343421 0.71548208\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73390832 0.73389088 0.73390483 0.73389786 0.72118556 0.74314342\n",
      " 0.74317132 0.72146457 0.74242846 0.68340103 0.72090651 0.68793494\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73388739 0.73390483 0.73388391 0.73389437 0.74548706 0.74309809\n",
      " 0.72081937 0.7217924  0.70954048 0.74967215 0.69660504 0.72062748\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73385949 0.73385949 0.73385949 0.73385949 0.74239359 0.72080542\n",
      " 0.74240057 0.74310855 0.72099375 0.74256451 0.74169957 0.74237616\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73385949 0.73385949 0.73385949 0.73385949 0.74239708 0.72061034\n",
      " 0.74240057 0.74346079 0.74235174 0.72128322 0.74138569 0.74236221\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73385949 0.73385949 0.73385949 0.73385949 0.74104041 0.70753875\n",
      " 0.7379574  0.74314342 0.74192277 0.73299462 0.74122874 0.74196462\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73385949 0.73385949 0.73385949 0.73385949 0.74104041 0.70490562\n",
      " 0.73796089 0.74345033 0.74151124 0.73621012 0.73999414 0.74198206\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74721691 0.73385949 0.73982674 0.7456789  0.72037303 0.66666667\n",
      " 0.69432781 0.73664956 0.73617874 0.73395714 0.72326074 0.74235872\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7472204  0.73385949 0.73982325 0.73870375 0.72037303 1.\n",
      " 0.69411158 0.73906294 0.73617874 0.73396412 0.71371177 0.74236221\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66161638 0.66161106 0.66161532 0.66161318 0.69809239 0.69052485\n",
      " 0.69052278 0.69811907 0.6901133  0.71071424 0.69824476 0.70799508\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66160999 0.66161531 0.66160893 0.66161212 0.68994152 0.69051658\n",
      " 0.69807968 0.69842631 0.69997902 0.68926062 0.70292227 0.69709769\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66160149 0.66160149 0.66160149 0.66160149 0.69049088 0.69807571\n",
      " 0.69049288 0.69051481 0.6984335  0.69018138 0.69056806 0.69048585\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66160149 0.66160149 0.66160149 0.66160149 0.69049187 0.69855112\n",
      " 0.69049288 0.69052262 0.69047881 0.69843323 0.69053514 0.69048184\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66160149 0.66160149 0.66160149 0.66160149 0.69061013 0.69397954\n",
      " 0.6910871  0.69051476 0.69049399 0.69167489 0.69058137 0.69051624\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66160149 0.66160149 0.66160149 0.66160149 0.69061013 0.69401511\n",
      " 0.69108811 0.69051962 0.69052436 0.69153106 0.69081842 0.69052126\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66352748 0.66160149 0.66251928 0.67234435 0.69297966 0.33333333\n",
      " 0.69365596 0.69101102 0.69152198 0.66163127 0.69241443 0.69048084\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66352852 0.66160149 0.66251823 0.66225167 0.69297966 0.5\n",
      " 0.69359716 0.69088977 0.69152198 0.6616334  0.69346097 0.69048184\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"loss\": [\"hinge\", \"log_loss\", \"modified_huber\"], # \"squared_hinge\", \"perceptron\"], \n",
    "             # \"squared_error\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"],\n",
    "    \"penalty\": [\"l2\", \"l1\", \"elasticnet\", None], \n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"learning_rate\": [\"constant\", \"optimal\", \"invscaling\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_data()\n",
    "model = SGDClassifier(early_stopping=True, n_iter_no_change=5)\n",
    "result = grid_search_eval(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33e5fb88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T06:58:22.927720Z",
     "start_time": "2022-12-26T06:58:17.176103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " SGDClassifier(class_weight='balanced', early_stopping=True,\n",
      "              loss='modified_huber', penalty='l1')\n",
      "0.6993028333077578\n",
      "0.6890664201769444\n",
      "오차 행렬\n",
      "[[49254 22438]\n",
      " [ 1109  2929]]\n",
      "정확도: 0.6891, 정밀도: 0.1155, 재현율: 0.7254, F1: 0.1992, AUC:0.7732\n",
      "==================================================================================================== \n",
      " SGDClassifier(class_weight='balanced', early_stopping=True,\n",
      "              loss='modified_huber', penalty=None)\n",
      "0.7031531185915768\n",
      "0.6810246929882477\n",
      "오차 행렬\n",
      "[[48578 23114]\n",
      " [ 1042  2996]]\n",
      "정확도: 0.6810, 정밀도: 0.1147, 재현율: 0.7420, F1: 0.1988, AUC:0.7754\n",
      "==================================================================================================== \n",
      " SGDClassifier(early_stopping=True, loss='modified_huber')\n",
      "0.7047783295900004\n",
      "0.6759276376601083\n",
      "오차 행렬\n",
      "[[48148 23544]\n",
      " [  998  3040]]\n",
      "정확도: 0.6759, 정밀도: 0.1144, 재현율: 0.7528, F1: 0.1986, AUC:0.7706\n",
      "==================================================================================================== \n",
      " SGDClassifier(early_stopping=True, loss='modified_huber', penalty='elasticnet')\n",
      "0.7048149491511237\n",
      "0.6759276376601083\n",
      "오차 행렬\n",
      "[[48148 23544]\n",
      " [  998  3040]]\n",
      "정확도: 0.6759, 정밀도: 0.1144, 재현율: 0.7528, F1: 0.1986, AUC:0.7745\n",
      "==================================================================================================== \n",
      " SGDClassifier(alpha=0.001, early_stopping=True, loss='log_loss', penalty='l1')\n",
      "0.704807973996624\n",
      "0.6759276376601083\n",
      "오차 행렬\n",
      "[[48148 23544]\n",
      " [  998  3040]]\n",
      "정확도: 0.6759, 정밀도: 0.1144, 재현율: 0.7528, F1: 0.1986, AUC:0.7752\n"
     ]
    }
   ],
   "source": [
    "grid_search_eval_precision(model, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1600e9cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T07:27:59.660963Z",
     "start_time": "2022-12-26T07:27:59.622221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mean_test_precision\n",
      "param_alpha                     \n",
      "0.0001                  0.228381\n",
      "0.0010                  0.227389\n",
      "0.0100                  0.227110\n",
      "0.1000                  0.219048\n",
      "                    mean_test_precision\n",
      "param_class_weight                     \n",
      "0                              0.225969\n",
      "balanced                       0.224995\n",
      "                     mean_test_precision\n",
      "param_learning_rate                     \n",
      "constant                        0.000000\n",
      "invscaling                      0.000000\n",
      "optimal                         0.676447\n",
      "                mean_test_precision\n",
      "param_loss                         \n",
      "hinge                      0.220713\n",
      "log_loss                   0.225153\n",
      "modified_huber             0.230581\n",
      "               mean_test_precision\n",
      "param_penalty                     \n",
      "0                         0.227678\n",
      "elasticnet                0.227545\n",
      "l1                        0.219262\n",
      "l2                        0.227444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ParkMinjeong\\AppData\\Local\\Temp\\ipykernel_19700\\1993093451.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(result.groupby(col).mean()[[\"mean_test_precision\"]])\n",
      "C:\\Users\\ParkMinjeong\\AppData\\Local\\Temp\\ipykernel_19700\\1993093451.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(result.groupby(col).mean()[[\"mean_test_precision\"]])\n",
      "C:\\Users\\ParkMinjeong\\AppData\\Local\\Temp\\ipykernel_19700\\1993093451.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(result.groupby(col).mean()[[\"mean_test_precision\"]])\n",
      "C:\\Users\\ParkMinjeong\\AppData\\Local\\Temp\\ipykernel_19700\\1993093451.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(result.groupby(col).mean()[[\"mean_test_precision\"]])\n",
      "C:\\Users\\ParkMinjeong\\AppData\\Local\\Temp\\ipykernel_19700\\1993093451.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(result.groupby(col).mean()[[\"mean_test_precision\"]])\n"
     ]
    }
   ],
   "source": [
    "# result.fillna(0, inplace=True)\n",
    "for col in result.columns:\n",
    "    if col.startswith(\"param_\"):\n",
    "        print(result.groupby(col).mean()[[\"mean_test_precision\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8d81d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T07:45:30.217169Z",
     "start_time": "2022-12-26T07:36:20.478625Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    286742\n",
      "1.0    286742\n",
      "Name: HEARTDISEASE, dtype: int64\n",
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l2; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l2; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l1; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l1; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=None; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=None; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   1.3s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   1.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   1.2s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log, penalty=l2; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log, penalty=l2; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log, penalty=l1; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log, penalty=l1; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log, penalty=None; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log, penalty=None; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=log, penalty=None; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   1.2s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l2; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l1; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=None; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=None; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=log, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   1.1s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   1.2s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   1.1s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   1.2s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   1.3s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   1.2s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log, penalty=l2; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log, penalty=l2; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log, penalty=l2; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log, penalty=l1; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log, penalty=l1; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log, penalty=None; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log, penalty=None; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=log, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   1.1s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   1.2s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   1.1s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   1.2s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=None; total time=   1.1s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=None; total time=   1.2s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   1.3s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   1.1s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l1; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log, penalty=None; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log, penalty=None; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=log, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   1.1s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log, penalty=l1; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log, penalty=l1; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log, penalty=l1; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log, penalty=None; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log, penalty=None; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=log, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   1.2s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   1.3s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   1.2s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   1.2s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l1; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l1; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log, penalty=None; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log, penalty=None; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=log, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   1.3s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.6s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=None; total time=   1.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l2; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log_loss, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=modified_huber, penalty=None; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log, penalty=l2; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log, penalty=elasticnet; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log, penalty=None; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log, penalty=None; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=log, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   1.4s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   1.3s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_hinge, penalty=None; total time=   1.2s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   1.3s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   1.2s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=perceptron, penalty=None; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      " SGDClassifier(class_weight='balanced', early_stopping=True, loss='log',\n",
      "              penalty=None)\n",
      "0.7082324877415935\n",
      "0.6692988247722171\n",
      "오차 행렬\n",
      "[[47694 23988]\n",
      " [ 1056  2992]]\n",
      "정확도: 0.6693, 정밀도: 0.1109, 재현율: 0.7391, F1: 0.1929, AUC:0.7650\n",
      "==================================================================================================== \n",
      " SGDClassifier(early_stopping=True, loss='log_loss', penalty='elasticnet')\n",
      "0.7080110343095884\n",
      "0.6697213785818038\n",
      "오차 행렬\n",
      "[[47732 23950]\n",
      " [ 1062  2986]]\n",
      "정확도: 0.6697, 정밀도: 0.1109, 재현율: 0.7376, F1: 0.1927, AUC:0.7653\n",
      "==================================================================================================== \n",
      " SGDClassifier(early_stopping=True, loss='modified_huber')\n",
      "0.7071967134218217\n",
      "0.6728509177340551\n",
      "오차 행렬\n",
      "[[48003 23679]\n",
      " [ 1096  2952]]\n",
      "정확도: 0.6729, 정밀도: 0.1108, 재현율: 0.7292, F1: 0.1924, AUC:0.7636\n",
      "SGDClassifier(early_stopping=True, loss='perceptron', penalty='elasticnet')\n",
      "==================================================================================================== \n",
      " SGDClassifier(early_stopping=True, loss='perceptron', penalty='elasticnet')\n",
      "0.6944169322945366\n",
      "0.5922619833619438\n",
      "오차 행렬\n",
      "[[41678 30004]\n",
      " [  874  3174]]\n",
      "정확도: 0.5923, 정밀도: 0.0957, 재현율: 0.7841, F1: 0.1705, AUC:0.7636\n",
      "SGDClassifier(alpha=0.001, early_stopping=True, loss='perceptron',\n",
      "              penalty='elasticnet')\n",
      "==================================================================================================== \n",
      " SGDClassifier(alpha=0.001, early_stopping=True, loss='perceptron',\n",
      "              penalty='elasticnet')\n",
      "0.6243016370116691\n",
      "0.851842070513667\n",
      "오차 행렬\n",
      "[[63011  8671]\n",
      " [ 2549  1499]]\n",
      "정확도: 0.8518, 정밀도: 0.1474, 재현율: 0.3703, F1: 0.2109, AUC:0.7636\n",
      "==================================================================================================== \n",
      " SGDClassifier(alpha=0.01, class_weight='balanced', early_stopping=True,\n",
      "              loss='log_loss', penalty=None)\n",
      "0.7080232404042659\n",
      "0.6697213785818038\n",
      "오차 행렬\n",
      "[[47732 23950]\n",
      " [ 1062  2986]]\n",
      "정확도: 0.6697, 정밀도: 0.1109, 재현율: 0.7376, F1: 0.1927, AUC:0.7647\n",
      "SGDClassifier(alpha=0.01, early_stopping=True, loss='perceptron', penalty='l1')\n",
      "==================================================================================================== \n",
      " SGDClassifier(alpha=0.01, early_stopping=True, loss='perceptron', penalty='l1')\n",
      "0.6096072427478361\n",
      "0.6048725736167965\n",
      "오차 행렬\n",
      "[[43374 28308]\n",
      " [ 1615  2433]]\n",
      "정확도: 0.6049, 정밀도: 0.0791, 재현율: 0.6010, F1: 0.1399, AUC:0.7647\n",
      "SGDClassifier(alpha=0.01, early_stopping=True, loss='perceptron', penalty=None)\n",
      "==================================================================================================== \n",
      " SGDClassifier(alpha=0.01, early_stopping=True, loss='perceptron', penalty=None)\n",
      "0.5827520907296455\n",
      "0.26984022184075\n",
      "오차 행렬\n",
      "[[16654 55028]\n",
      " [  267  3781]]\n",
      "정확도: 0.2698, 정밀도: 0.0643, 재현율: 0.9340, F1: 0.1203, AUC:0.7647\n",
      "SGDClassifier(alpha=0.1, class_weight='balanced', early_stopping=True,\n",
      "              loss='squared_hinge', penalty=None)\n",
      "==================================================================================================== \n",
      " SGDClassifier(alpha=0.1, class_weight='balanced', early_stopping=True,\n",
      "              loss='squared_hinge', penalty=None)\n",
      "0.7078697923568923\n",
      "0.6702891852634358\n",
      "오차 행렬\n",
      "[[47782 23900]\n",
      " [ 1069  2979]]\n",
      "정확도: 0.6703, 정밀도: 0.1108, 재현율: 0.7359, F1: 0.1926, AUC:0.7647\n",
      "SGDClassifier(alpha=0.1, early_stopping=True, loss='squared_hinge',\n",
      "              penalty='l1')\n",
      "==================================================================================================== \n",
      " SGDClassifier(alpha=0.1, early_stopping=True, loss='squared_hinge',\n",
      "              penalty='l1')\n",
      "0.6816667945400395\n",
      "0.6289845503763369\n",
      "오차 행렬\n",
      "[[44724 26958]\n",
      " [ 1139  2909]]\n",
      "정확도: 0.6290, 정밀도: 0.0974, 재현율: 0.7186, F1: 0.1715, AUC:0.7647\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"loss\": [\"hinge\", \"log_loss\", \"modified_huber\", \"log\", \"squared_hinge\", \"perceptron\"], \n",
    "    \"penalty\": [\"l2\", \"l1\", \"elasticnet\", None], \n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"learning_rate\": [\"optimal\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_data()\n",
    "model = SGDClassifier(early_stopping=True, n_iter_no_change=5)\n",
    "model_list, result = grid_search_eval(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c01de98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T08:08:11.450531Z",
     "start_time": "2022-12-26T08:08:11.418383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mean_test_precision\n",
      "param_alpha                     \n",
      "0.0001                  0.684921\n",
      "0.0010                  0.681320\n",
      "0.0100                  0.673683\n",
      "0.1000                  0.616062\n",
      "                    mean_test_precision\n",
      "param_class_weight                     \n",
      "0                              0.664689\n",
      "balanced                       0.663305\n",
      "                     mean_test_precision\n",
      "param_learning_rate                     \n",
      "optimal                         0.663997\n",
      "                mean_test_precision\n",
      "param_loss                         \n",
      "hinge                      0.663966\n",
      "log                        0.665197\n",
      "log_loss                   0.659705\n",
      "modified_huber             0.697445\n",
      "perceptron                 0.594889\n",
      "squared_hinge              0.702777\n",
      "               mean_test_precision\n",
      "param_penalty                     \n",
      "0                         0.688272\n",
      "elasticnet                0.683532\n",
      "l1                        0.599022\n",
      "l2                        0.685160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ParkMinjeong\\AppData\\Local\\Temp\\ipykernel_19700\\1993093451.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(result.groupby(col).mean()[[\"mean_test_precision\"]])\n",
      "C:\\Users\\ParkMinjeong\\AppData\\Local\\Temp\\ipykernel_19700\\1993093451.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(result.groupby(col).mean()[[\"mean_test_precision\"]])\n",
      "C:\\Users\\ParkMinjeong\\AppData\\Local\\Temp\\ipykernel_19700\\1993093451.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(result.groupby(col).mean()[[\"mean_test_precision\"]])\n",
      "C:\\Users\\ParkMinjeong\\AppData\\Local\\Temp\\ipykernel_19700\\1993093451.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(result.groupby(col).mean()[[\"mean_test_precision\"]])\n",
      "C:\\Users\\ParkMinjeong\\AppData\\Local\\Temp\\ipykernel_19700\\1993093451.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(result.groupby(col).mean()[[\"mean_test_precision\"]])\n"
     ]
    }
   ],
   "source": [
    "# result.fillna(0, inplace=True)\n",
    "for col in result.columns:\n",
    "    if col.startswith(\"param_\"):\n",
    "        print(result.groupby(col).mean()[[\"mean_test_precision\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42b9b4f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T08:10:06.787053Z",
     "start_time": "2022-12-26T08:10:05.820210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41678 30004]\n",
      " [  874  3174]]\n",
      "[[63011  8671]\n",
      " [ 2549  1499]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43374 28308]\n",
      " [ 1615  2433]]\n",
      "[[16654 55028]\n",
      " [  267  3781]]\n",
      "[[47782 23900]\n",
      " [ 1069  2979]]\n",
      "[[44724 26958]\n",
      " [ 1139  2909]]\n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    pred = model.predict(X_test)\n",
    "    try:\n",
    "        pred_proba = model.predict_proba(X_test)[:,1]\n",
    "        precision_recall_curve_plot(y_test, pred_proba)\n",
    "    except:\n",
    "        print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2edd864e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T08:27:13.996714Z",
     "start_time": "2022-12-26T08:21:27.450410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    286765\n",
      "1.0    286765\n",
      "Name: HEARTDISEASE, dtype: int64\n",
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   1.2s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   1.2s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   1.3s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   1.1s\n",
      "[CV] END alpha=0.0001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   1.3s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   1.1s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   1.1s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   1.2s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.001, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=None; total time=   1.1s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=None; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   1.2s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.6s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.01, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   1.1s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   1.3s\n",
      "[CV] END alpha=0.1, class_weight=balanced, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_error, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=huber, penalty=l2; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=huber, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   1.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=huber, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=huber, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.9s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=elasticnet; total time=   1.1s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   1.1s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=epsilon_insensitive, penalty=None; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l2; total time=   1.1s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=l1; total time=   1.0s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=elasticnet; total time=   0.7s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.8s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   0.6s\n",
      "[CV] END alpha=0.1, class_weight=None, learning_rate=optimal, loss=squared_epsilon_insensitive, penalty=None; total time=   2.1s\n",
      "========================================================================================================================================================================================================\n",
      "==================================================================================================== \n",
      " SGDClassifier(class_weight='balanced', early_stopping=True,\n",
      "              loss='squared_epsilon_insensitive', penalty=None)\n",
      "0.7034139452164665\n",
      "0.7387825168361284\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(None, dtype=object) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [39], line 27\u001b[0m, in \u001b[0;36mgrid_search_eval\u001b[1;34m(model, params)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     pred_proba \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(X_test)[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, best_model)\n",
      "File \u001b[1;32mD:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:127\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n",
      "File \u001b[1;32mD:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1222\u001b[0m, in \u001b[0;36mSGDClassifier._check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodified_huber\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobability estimates are not available for loss=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m   1224\u001b[0m     )\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: probability estimates are not available for loss='squared_epsilon_insensitive'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m prepare_data()\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m SGDClassifier(early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_iter_no_change\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m model_list, result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [39], line 37\u001b[0m, in \u001b[0;36mgrid_search_eval\u001b[1;34m(model, params)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28mprint\u001b[39m(best_model\u001b[38;5;241m.\u001b[39mscore(X_train, y_train))\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28mprint\u001b[39m(best_model\u001b[38;5;241m.\u001b[39mscore(X_test, y_test))\n\u001b[1;32m---> 37\u001b[0m         \u001b[43mget_clf_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_list, result\n",
      "Cell \u001b[1;32mIn [3], line 8\u001b[0m, in \u001b[0;36mget_clf_eval\u001b[1;34m(y_test, pred, pred_proba)\u001b[0m\n\u001b[0;32m      6\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_test, pred)\n\u001b[0;32m      7\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, pred)\n\u001b[1;32m----> 8\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_proba\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m오차 행렬\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion)\n",
      "File \u001b[1;32mD:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:550\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    548\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    549\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 550\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    553\u001b[0m     y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    554\u001b[0m ):\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;66;03m# do not support partial ROC computation for multiclass\u001b[39;00m\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m max_fpr \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n",
      "File \u001b[1;32mD:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\utils\\validation.py:907\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    899\u001b[0m         _assert_all_finite(\n\u001b[0;32m    900\u001b[0m             array,\n\u001b[0;32m    901\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    902\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    903\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    904\u001b[0m         )\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 907\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m \u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m    909\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    913\u001b[0m         )\n",
      "File \u001b[1;32mD:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\sklearn\\utils\\validation.py:325\u001b[0m, in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    326\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleton array \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m cannot be considered a valid collection.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m x\n\u001b[0;32m    327\u001b[0m         )\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;66;03m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array array(None, dtype=object) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"loss\": [\"squared_error\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"], \n",
    "    \"penalty\": [\"l2\", \"l1\", \"elasticnet\", None], \n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"learning_rate\": [\"optimal\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_data()\n",
    "model = SGDClassifier(early_stopping=True, n_iter_no_change=5)\n",
    "model_list, result = grid_search_eval(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c61cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T08:27:14.010641Z",
     "start_time": "2022-12-26T08:27:14.010641Z"
    }
   },
   "outputs": [],
   "source": [
    "# result.fillna(0, inplace=True)\n",
    "for col in result.columns:\n",
    "    if col.startswith(\"param_\"):\n",
    "        print(result.groupby(col).mean()[[\"mean_test_precision\"]])\n",
    "        \n",
    "for model in model_list:\n",
    "    pred = model.predict(X_test)\n",
    "    try:\n",
    "        pred_proba = model.predict_proba(X_test)[:,1]\n",
    "        precision_recall_curve_plot(y_test, pred_proba)\n",
    "    except:\n",
    "        print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1111a24",
   "metadata": {},
   "source": [
    "## SVM\n",
    "- 종류\n",
    "    - SVC\n",
    "    - LinearSVC\n",
    "    - NuSVC\n",
    "    - https://scikit-learn.org/stable/modules/svm.html#svm-classification\n",
    "- SVC 하이퍼 파라미터\n",
    "    - C: float, default=1.0\n",
    "    - kernel: {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} or callable, default=’rbf’\n",
    "    - degree: int, default=3\n",
    "    - gamma: {‘scale’, ‘auto’} or float, default=’scale’\n",
    "    - coef0: float, default=0.0\n",
    "    - shrinking: bool, default=True\n",
    "    - probability: bool, default=False\n",
    "    - tol: float, default=1e-3\n",
    "    - cache_size: float, default=200\n",
    "    - class_weight: dict or ‘balanced’, default=None\n",
    "    - verbose: bool, default=False\n",
    "    - max_iter: int, default=-1\n",
    "    - decision_function_shape: {‘ovo’, ‘ovr’}, default=’ovr’\n",
    "    - break_ties: bool, default=False\n",
    "- NuSVC 하이퍼 파라미터\n",
    "    - nu: float, default=0.5\n",
    "    - kernel: {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} or callable, default=’rbf’\n",
    "    - degree: int, default=3\n",
    "    - gamma: {‘scale’, ‘auto’} or float, default=’scale’\n",
    "    - coef0: float, default=0.0\n",
    "    - shrinking: bool, default=True\n",
    "    - probability: bool, default=False\n",
    "    - tol: float, default=1e-3\n",
    "    - cache_size: float, default=200\n",
    "    - class_weight: dict or ‘balanced’, default=None\n",
    "    - verbose: bool, default=False\n",
    "    - max_iter: int, default=-1\n",
    "    - decision_function_shape: {‘ovo’, ‘ovr’}, default=’ovr’\n",
    "    - break_ties: bool, default=False\n",
    "- LinearSVC 하이퍼 파라미터\n",
    "    - penalty: {‘l1’, ‘l2’}, default=’l2’\n",
    "    - loss: {‘hinge’, ‘squared_hinge’}, default=’squared_hinge’\n",
    "    - dual: bool, default=True\n",
    "    - tol: float, default=1e-4\n",
    "    - C: float, default=1.0\n",
    "    - multi_class: {‘ovr’, ‘crammer_singer’}, default=’ovr’\n",
    "    - fit_intercept: bool, default=True\n",
    "    - intercept_scaling: float, default=1.0\n",
    "    - class_weight: dict or ‘balanced’, default=None\n",
    "    - verbose: int, default=0\n",
    "    - random_state: int, RandomState instance or None, default=None\n",
    "    - max_iter: int, default=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a2eeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T08:33:17.108264Z",
     "start_time": "2022-12-23T08:31:53.834727Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "model = SVC(max_iter=100, probability=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4496d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T08:48:16.174646Z",
     "start_time": "2022-12-23T08:48:03.295296Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearSVC(max_iter=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a99f6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-23T08:48:34.298Z"
    }
   },
   "outputs": [],
   "source": [
    "model = NuSVC(max_iter=100, probability=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79324bf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T07:17:42.418304Z",
     "start_time": "2022-12-23T07:17:42.401992Z"
    }
   },
   "source": [
    "# 서대훈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8713d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T05:24:49.030333Z",
     "start_time": "2022-12-23T05:24:49.017366Z"
    }
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f41d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T07:14:06.530163Z",
     "start_time": "2022-12-23T07:14:06.335741Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd096ee",
   "metadata": {},
   "source": [
    "## LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27249739",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T07:13:20.852482Z",
     "start_time": "2022-12-23T07:13:16.623714Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model = LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af62c849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T06:30:17.390180Z",
     "start_time": "2022-12-23T06:30:17.382142Z"
    }
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef48d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T06:31:47.526489Z",
     "start_time": "2022-12-23T06:31:11.700919Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237db66e",
   "metadata": {},
   "source": [
    "# 손지호"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9df1a5",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa4e55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T07:14:09.003437Z",
     "start_time": "2022-12-23T07:14:08.261998Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb5c18",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564edf20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T07:13:13.763247Z",
     "start_time": "2022-12-23T07:12:59.423159Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dc3797b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-26T07:09:41.630792Z",
     "start_time": "2022-12-26T07:09:41.375303Z"
    }
   },
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "Invalid Parameter format for learning_rate expect float but value='[0.01, 0.05, 0.1, 0, 15]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m wlist \u001b[38;5;241m=\u001b[39m [(dtrain,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m),(dtest,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m) ] \u001b[38;5;66;03m# eval 평가용\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 모델학습\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;43;03m#                      early_stopping_rounds = 100, \u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwlist\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\study\\Anaconda\\envs\\multicampus\\lib\\site-packages\\xgboost\\core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: Invalid Parameter format for learning_rate expect float but value='[0.01, 0.05, 0.1, 0, 15]'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(data = X_train, label = y_train)\n",
    "dtest = xgb.DMatrix(data = X_test, label = y_test)\n",
    "\n",
    "# 파라미터 설정\n",
    "params = {\n",
    "    'n_estimators' : [100,200,300,400,500],\n",
    "    'eta' : [0.01,0.05,0.1,0,15], # learning_rate\n",
    "    'max_depth' : [3,5,7,10,15],\n",
    "    'gamma' : [0,1,2,3],\n",
    "    'colsample_bytree' : 0.8\n",
    "}\n",
    "\n",
    "# 모델개수\n",
    "num_rounds = 400\n",
    "\n",
    "wlist = [(dtrain,'train'),(dtest,'eval') ] # eval 평가용\n",
    "\n",
    "# 모델학습\n",
    "xgb_model = xgb.train(params = params,\n",
    "                      dtrain = dtrain,\n",
    "                      num_boost_round = num_rounds,\n",
    "#                      early_stopping_rounds = 100, \n",
    "                      evals = wlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca4d07",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4bfdf0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-23T06:47:47.678Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5517ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eduvenv",
   "language": "python",
   "name": "eduvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "498.844px",
    "left": "1545px",
    "right": "20px",
    "top": "142px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
